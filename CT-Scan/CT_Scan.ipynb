{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CT-Scan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrei-micuda/ML-Labs-2021/blob/master/CT-Scan/CT_Scan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qROPhEtp1snz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e1a9b9-f82b-40a5-c59c-e22296dab701"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_name = \"/content/drive/MyDrive/ct-scan.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall(\"ct-scan\")\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g6v-ciU3Kc2ToOtjGBDLtEHsaZfi8xUHWojPazgzonSlrjahM1AZxs\n",
            "Mounted at /content/drive\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLLNu-HM7xKU"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from tensorflow.keras import layers, models, preprocessing, callbacks, regularizers, constraints\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_height, img_width, img_channels = 50, 50, 1\n",
        "\n",
        "\n",
        "def process_csv_entry(entry):\n",
        "    img_path, label = entry.strip().split(\",\")\n",
        "    return img_path, int(label)\n",
        "\n",
        "def decode_img(img):\n",
        "  img = PIL.Image.open(img)\n",
        "  return np.asarray(img)\n",
        "\n",
        "def load_data(dir_name, csv_file, has_labels=True):\n",
        "  features = []\n",
        "  if has_labels:\n",
        "    labels = []\n",
        "  with open(csv_file, \"r\") as fin:\n",
        "    for entry in fin:\n",
        "      img_path = entry.strip()\n",
        "      if has_labels:\n",
        "        img_path, label = process_csv_entry(entry)\n",
        "      \n",
        "      img = decode_img(dir_name + \"/\" + img_path)\n",
        "      features.append(img)\n",
        "      if has_labels:\n",
        "        labels.append(label)\n",
        "  if has_labels:\n",
        "    return np.stack(features), np.stack(labels)\n",
        "  return np.stack(features)\n",
        "\n",
        "def preprocess_images(imgs):\n",
        "  processed_images = np.copy(imgs)\n",
        "  processed_images = processed_images / 255.0\n",
        "  # processed_images = 255 - processed_images\n",
        "  mean = np.mean(processed_images, axis=(1, 2), keepdims=True)\n",
        "  std = np.std(processed_images, axis=(1, 2), keepdims=True)\n",
        "  processed_images = (processed_images - mean) / std\n",
        "  return processed_images\n",
        "  # ones = np.ones(2500).reshape((50, 50))\n",
        "  # return np.subtract(ones, processed_images)\n",
        "\n",
        "\n",
        "def show_data_sample(imgs, labels):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    # ones = np.ones(2500).reshape((50, 50))\n",
        "    plt.imshow(imgs[i])\n",
        "    # plt.imshow(np.subtract(ones, imgs[i]))\n",
        "    # plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oigUuBqdc5"
      },
      "source": [
        "class_names = [\"native\", \"arterial\", \"venous\"]\n",
        "\n",
        "train_ds, train_labels = load_data(r\"/content/ct-scan/train\", r\"/content/ct-scan/train.txt\")\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "# show_data_sample(train_ds, train_labels)\n",
        "\n",
        "validation_ds, validation_labels = load_data(r\"/content/ct-scan/validation\", r\"/content/ct-scan/validation.txt\")\n",
        "validation_labels = tf.keras.utils.to_categorical(validation_labels)\n",
        "\n",
        "test_ds = load_data(r\"/content/ct-scan/test\", r\"/content/ct-scan/test.txt\", has_labels=False)\n",
        "\n",
        "train_images = tf.expand_dims(preprocess_images(train_ds), axis=-1)\n",
        "validation_images = tf.expand_dims(preprocess_images(validation_ds), axis=-1)\n",
        "test_images = tf.expand_dims(preprocess_images(test_ds), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V4fnKwS7E6E"
      },
      "source": [
        "We are going to make 2 utility functions for quick and dirty model testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CVD-Pnp7N6x"
      },
      "source": [
        "def add_layer(model, layer, is_input_layer=False, is_output_layer=False):\n",
        "  weight_decay = 1e-4\n",
        "  parts = [part.strip() for part in layer.split(\"~\")]\n",
        "  for part in parts:\n",
        "    if part.startswith(\"CL\"):\n",
        "      part = part[2:]\n",
        "      filters, kernel_size_and_padding = part.split(\"C\")\n",
        "      filters = int(filters)\n",
        "      kernel_size, padd = int(kernel_size_and_padding[:-1]), kernel_size_and_padding[-1]\n",
        "      if is_input_layer:\n",
        "        model.add(\n",
        "          layers.Conv2D(\n",
        "            filters,\n",
        "            (kernel_size, kernel_size),\n",
        "            activation=\"relu\",\n",
        "            input_shape=(img_height, img_width, img_channels),\n",
        "            padding=\"same\" if padd == \"S\" else \"valid\"\n",
        "            # kernel_regularizer=regularizers.l2(),\n",
        "          )\n",
        "          )\n",
        "      else:\n",
        "        model.add(\n",
        "          layers.Conv2D(\n",
        "            filters,\n",
        "            (kernel_size, kernel_size),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\" if padd == \"S\" else \"valid\"\n",
        "            # kernel_regularizer=regularizers.l2(weight_decay),\n",
        "            )\n",
        "        )\n",
        "    elif part.startswith(\"P\"):\n",
        "      pool_size = int(part[1:])\n",
        "      # model.add(layers.AvgPool2D(pool_size=(pool_size, pool_size)))\n",
        "      model.add(layers.MaxPool2D(pool_size=(pool_size, pool_size)))\n",
        "    elif part.startswith(\"BN\"):\n",
        "      if is_input_layer:\n",
        "        model.add(layers.BatchNormalization(input_shape=(img_height, img_width, img_channels)))\n",
        "      else:\n",
        "        model.add(layers.BatchNormalization())\n",
        "    elif part.startswith(\"DO\"):\n",
        "      rate = float(part[2:]) / 100.0\n",
        "      if is_input_layer:\n",
        "        model.add(layers.Dropout(rate, input_shape=(img_height, img_width, img_channels)))\n",
        "      else:\n",
        "        model.add(layers.Dropout(rate))\n",
        "    elif part.startswith(\"F\"):\n",
        "      model.add(layers.Flatten())\n",
        "    elif part.startswith(\"D\"):\n",
        "      units = int(part[1:])\n",
        "      model.add(\n",
        "          layers.Dense(\n",
        "              units,\n",
        "              activation=\"softmax\" if is_output_layer else \"relu\",\n",
        "              kernel_constraint=constraints.MaxNorm(3),\n",
        "          )\n",
        "      )\n",
        "\n",
        "\n",
        "def create_model(pattern):\n",
        "  model = models.Sequential()\n",
        "  layers = [layer.strip() for layer in pattern.split(\"->\")]\n",
        "  num_layers = len(layers)\n",
        "  # model.add(\n",
        "  #   tf.keras.layers.experimental.preprocessing.Normalization(\n",
        "  #       input_shape=(50, 50, 1)\n",
        "  #   )\n",
        "  # )\n",
        "  # model.add(tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1))\n",
        "  for i, layer in enumerate(layers):\n",
        "    add_layer(model, layer, is_input_layer=(i == 0), is_output_layer=(i == num_layers - 1))\n",
        "  # model.compile(\n",
        "  #   optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "  #   loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "  #   metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyPpoCJd7sQx"
      },
      "source": [
        "callbacks = [           \n",
        "    tf.keras.callbacks.ModelCheckpoint('/content/ct-scan/best-weights.h5',\n",
        "      save_weights_only=True,\n",
        "      monitor='val_accuracy',\n",
        "      mode='max',\n",
        "      save_best_only=True),\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        mode=\"max\",\n",
        "                        patience=10,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "]\n",
        "\n",
        "def model_testing(model_pattern, epochs, show_graphs=True):\n",
        "  # model_patterns = [\"CL48C5~P2~BN~DO1 -> CL64C5~P2~BN~DO1 -> CL128C5~BN~DO1 -> F -> D512 -> D512 -> D3\"]\n",
        "  model = create_model(model_pattern)\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0017, epsilon=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  datagen = preprocessing.image.ImageDataGenerator(\n",
        "    # height_shift_range=[-5, 5],\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    # featurewise_center=True,\n",
        "    # featurewise_std_normalization=True\n",
        "    # zca_whitening=True\n",
        "    # zoom_range=[0.7, 1.0]\n",
        "  )\n",
        "  datagen.fit(train_images)\n",
        "  train_images_it = datagen.flow(train_images, train_labels)\n",
        "  validation_images_it = datagen.flow(validation_images, validation_labels)\n",
        "\n",
        "\n",
        "  history = model.fit(\n",
        "    train_images_it,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_images_it,\n",
        "    callbacks=callbacks,\n",
        "    # steps_per_epoch=468,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  if show_graphs:\n",
        "    # PLOT ACCURACIES\n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 12))\n",
        "    fig.suptitle(model_pattern)\n",
        "    ax1.plot(history.history[\"val_accuracy\"], linestyle=\"solid\", color=\"orange\")\n",
        "    ax1.plot(history.history[\"accuracy\"], linestyle=\"solid\", color=\"blue\")\n",
        "    ax1.set_xticks(range((epochs)))\n",
        "    ax1.set_title(\"Accuracies\")\n",
        "    ax1.set_ylabel(\"accuracy\")\n",
        "    ax1.set_xlabel(\"epoch\")\n",
        "    ax1.legend([\"val_accuracy\", \"accuracy\"], loc=\"upper left\")\n",
        "\n",
        "    ax2.plot(history.history[\"val_loss\"], linestyle=\"solid\", color=\"orange\")\n",
        "    ax2.plot(history.history[\"loss\"], linestyle=\"solid\", color=\"blue\")\n",
        "    ax2.set_xticks(range((epochs)))\n",
        "    ax2.set_title(\"Loss\")\n",
        "    ax2.set_ylabel(\"loss\")\n",
        "    ax2.set_xlabel(\"epoch\")\n",
        "    ax2.legend([\"val_loss\", \"loss\"], loc=\"upper left\")\n",
        "    # axes = plt.gca()\n",
        "    # axes.set_ylim([0.98, 1])\n",
        "    plt.show()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ndrEHH7yVx"
      },
      "source": [
        "# model_testing(\"CL12C7~CL12C7~BN~P2~DO50 -> CL24C5~CL24C5~BN~P2~DO50 -> F -> D120~DO50 -> D64~DO50 -> D3\", 50)\n",
        "# model = model_testing(\"CL32C7V~DO25~CL132C7V~DO25~BN~P2 -> CL64C5V~DO25~CL64C5V~DO25~BN~P2 -> F -> D128~DO50 -> D128~DO50 -> D3\", 50)\n",
        "#  model = model_testing(\"CL32C7V~CL32C7V~BN~P2~DO36.1 -> CL64C5V~CL64C5V~BN~P2~DO36.4 -> F -> D128~DO22.7 -> D128~DO27.4 -> D3\", 100, show_graphs=True)\n",
        "# model = model_testing(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D128~DO26 -> D128~DO62 -> D3\", 100, show_graphs=True)\n",
        "model = model_testing(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 20, show_graphs=True)\n",
        "# {'Dropout': 0.1878338127435366, 'Dropout_1': 0.8293042185943654, 'Dropout_2': 0.2698783541301023, 'Dropout_3': 0.6213265636979889}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHf-gSgFUWYz"
      },
      "source": [
        "model = model_testing(\"BN -> CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 30, show_graphs=True)\n",
        "\n",
        "# show_data_sample(test_ds, train_labels)\n",
        "model.load_weights(\"/content/ct-scan/best-weights.h5\")\n",
        "predictions = np.argmax(model.predict(test_images), axis=1)\n",
        "with open(\"/content/ct-scan/test.txt\") as fin:\n",
        "  test_image_names = [line.strip() for line in fin.readlines()]\n",
        "with open(\"/content/ct-scan/submission.txt\", 'w') as fout:\n",
        "  fout.write(\"id,label\\n\")\n",
        "  for i, img in enumerate(test_image_names):\n",
        "    fout.write(f\"{img},{predictions[i]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydj0dRXzDj4A"
      },
      "source": [
        "callbackLst = [           \n",
        "  tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode=\"max\",\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        "  )\n",
        "]\n",
        "\n",
        "def model_predict(model_pattern, epochs):\n",
        "  model = create_model(model_pattern)\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0017, epsilon=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"])\n",
        "  \n",
        "  test_ds = load_data(r\"/content/ct-scan/test\", r\"/content/ct-scan/test.txt\", has_labels=False)\n",
        "\n",
        "  # train_images = tf.expand_dims(preprocess_images(train_ds), axis=-1)\n",
        "  # validation_images = tf.expand_dims(preprocess_images(validation_ds), axis=-1)\n",
        "  # test_images = tf.expand_dims(preprocess_images(test_ds), axis=-1)\n",
        "  train_images = tf.expand_dims(train_ds, axis=-1)\n",
        "  validation_images = tf.expand_dims(validation_ds, axis=-1)\n",
        "  test_images = tf.expand_dims(test_ds, axis=-1)\n",
        "\n",
        "  train_datagen = preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    # featurewise_center=True,\n",
        "    # featurewise_std_normalization=True,\n",
        "    rescale=1./255\n",
        "  )\n",
        "  train_datagen.fit(train_images)\n",
        "  train_images_it = train_datagen.flow(train_images, train_labels)\n",
        "\n",
        "\n",
        "  test_datagen = preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rescale=1./255\n",
        "  )\n",
        "  test_datagen.fit(train_images)\n",
        "  validation_images_it = test_datagen.flow(validation_images, validation_labels)\n",
        "  test_images_it = test_datagen.flow(test_images)\n",
        "\n",
        "\n",
        "  history = model.fit(\n",
        "    train_images_it,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_images_it,\n",
        "    callbacks=callbackLst,\n",
        "    # steps_per_epoch=468,\n",
        "    # shuffle=True,\n",
        "  )\n",
        "\n",
        "  predictions = np.argmax(model.predict(test_images), axis=1)\n",
        "  with open(\"/content/ct-scan/test.txt\") as fin:\n",
        "    test_image_names = [line.strip() for line in fin.readlines()]\n",
        "  with open(\"/content/ct-scan/submission.txt\", 'w') as fout:\n",
        "    fout.write(\"id,label\\n\")\n",
        "    for i, img in enumerate(test_image_names):\n",
        "      fout.write(f\"{img},{predictions[i]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBB8izkUROaC"
      },
      "source": [
        "model_predict(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KFB6-AvYqXg"
      },
      "source": [
        "callbacks = [             \n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        mode=\"max\",\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "]\n",
        "\n",
        "def lr_comparison(model_pattern, epochs):\n",
        "    lrs = [0.0015, 0.0016, 0.0017, 0.0018, 0.0019, 0.002]\n",
        "    history = [0] * len(lrs)\n",
        "    for i, lr in enumerate(lrs):\n",
        "        model = create_model(model_pattern)\n",
        "        model.compile(\n",
        "          optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics=[\"accuracy\"])\n",
        "\n",
        "        # model.summary()\n",
        "\n",
        "        train_images = tf.expand_dims(preprocess_images(train_ds), axis=-1)\n",
        "        datagen = preprocessing.image.ImageDataGenerator(\n",
        "            # height_shift_range=[-5, 5],\n",
        "            horizontal_flip=True,\n",
        "            rotation_range=15,\n",
        "            # vertical_flip=True,\n",
        "            # zoom_range=[0.8, 1.2]\n",
        "        )\n",
        "        train_images_it = datagen.flow(tf.expand_dims(train_ds, axis=-1), train_labels)\n",
        "        validation_images = tf.expand_dims(preprocess_images(validation_ds), axis=-1)\n",
        "\n",
        "        history[i] = model.fit(\n",
        "            train_images_it,\n",
        "            epochs=epochs,\n",
        "            validation_data=(validation_images, validation_labels),\n",
        "            # callbacks=[callback],\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "    styles = [\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "    ]\n",
        "\n",
        "    # PLOT ACCURACIES\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(len(lrs)):\n",
        "        plt.plot(\n",
        "            history[i].history[\"val_accuracy\"],\n",
        "            linestyle=styles[i],\n",
        "            color=np.random.rand(\n",
        "                3,\n",
        "            ),\n",
        "        )\n",
        "    plt.title(\"Model Architecture\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend(lrs, loc=\"upper left\")\n",
        "    # axes = plt.gca()\n",
        "    # axes.set_ylim([0.98, 1])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOo3f-3paZ1M"
      },
      "source": [
        "# lr_comparison(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-UJyJsUmazD"
      },
      "source": [
        "callbackLst = [             \n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        mode=\"max\",\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "]\n",
        "\n",
        "def epsilon_comparison(model_pattern, epochs):\n",
        "    epsilons = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
        "    history = [0] * len(epsilons)\n",
        "    for i, epsilon in enumerate(epsilons):\n",
        "        model = create_model(model_pattern)\n",
        "        model.compile(\n",
        "          optimizer=tf.keras.optimizers.Adam(learning_rate=0.0017, epsilon=epsilon),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics=[\"accuracy\"])\n",
        "\n",
        "        # model.summary()\n",
        "\n",
        "        train_images = tf.expand_dims(preprocess_images(train_ds), axis=-1)\n",
        "        datagen = preprocessing.image.ImageDataGenerator(\n",
        "            # height_shift_range=[-5, 5],\n",
        "            horizontal_flip=True,\n",
        "            rotation_range=15,\n",
        "            # vertical_flip=True,\n",
        "            # zoom_range=[0.8, 1.2]\n",
        "        )\n",
        "        train_images_it = datagen.flow(tf.expand_dims(train_ds, axis=-1), train_labels)\n",
        "        validation_images = tf.expand_dims(preprocess_images(validation_ds), axis=-1)\n",
        "\n",
        "        history[i] = model.fit(\n",
        "            train_images_it,\n",
        "            epochs=epochs,\n",
        "            validation_data=(validation_images, validation_labels),\n",
        "            callbacks=callbackLst,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "    styles = [\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "    ]\n",
        "\n",
        "    # PLOT ACCURACIES\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(len(epsilons)):\n",
        "        plt.plot(\n",
        "            history[i].history[\"val_accuracy\"],\n",
        "            linestyle=styles[i],\n",
        "            color=np.random.rand(\n",
        "                3,\n",
        "            ),\n",
        "        )\n",
        "    plt.title(\"Model Architecture\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend(epsilons, loc=\"upper left\")\n",
        "    # axes = plt.gca()\n",
        "    # axes.set_ylim([0.98, 1])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faG3n_ffoP-F"
      },
      "source": [
        "epsilon_comparison(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ9YfANzSg6f"
      },
      "source": [
        "Vom folosi `hyperas` pentru a optimiza hyperparametrii modelelor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCyAKQvhSnFR"
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "\n",
        "def data():\n",
        "  '''\n",
        "  Data providing function:\n",
        "  This function is separated from model() so that hyperopt\n",
        "  won't reload data for each evaluation run.\n",
        "  '''\n",
        "  (X_train, Y_train) = load_data(r\"/content/ct-scan/train\", r\"/content/ct-scan/train.txt\")\n",
        "  (X_test, Y_test) = load_data(r\"/content/ct-scan/validation\", r\"/content/ct-scan/validation.txt\")\n",
        "\n",
        "  X_train = tf.expand_dims(preprocess_images(X_train), axis=-1)\n",
        "  X_test = tf.expand_dims(preprocess_images(X_test), axis=-1)\n",
        "\n",
        "\n",
        "  Y_train = tf.keras.utils.to_categorical(Y_train)\n",
        "  Y_test = tf.keras.utils.to_categorical(Y_test)\n",
        "  return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test):\n",
        "  '''\n",
        "  Model providing function:\n",
        "  Create Keras model with double curly brackets dropped-in as needed.\n",
        "  Return value has to be a valid python dictionary with two customary keys:\n",
        "      - loss: Specify a numeric evaluation metric to be minimized\n",
        "      - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "  The last one is optional, though recommended, namely:\n",
        "      - model: specify the model just created so that we can later use it again.\n",
        "  '''\n",
        "  # \"CL32C7V~CL32C7V~BN~P2~DO50 -> CL64C5V~CL64C5V~BN~P2~DO50 -> F -> D128~DO50 -> D128~DO50 -> D3\"\n",
        "\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        mode=\"max\",\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(\n",
        "          layers.Conv2D(\n",
        "            32,\n",
        "            (7, 7),\n",
        "            input_shape=(50, 50, 1),\n",
        "            activation=\"relu\",\n",
        "            padding=\"valid\",\n",
        "            kernel_constraint=constraints.MaxNorm(3)\n",
        "          ))\n",
        "  model.add(\n",
        "          layers.Conv2D(\n",
        "            32,\n",
        "            (7, 7),\n",
        "            activation=\"relu\",\n",
        "            padding=\"valid\",\n",
        "            kernel_constraint=constraints.MaxNorm(3)\n",
        "          ))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout({{uniform(0.13, 0.23)}}))\n",
        "\n",
        "  model.add(\n",
        "          layers.Conv2D(\n",
        "            64,\n",
        "            (5, 5),\n",
        "            activation=\"relu\",\n",
        "            padding=\"valid\",\n",
        "            kernel_constraint=constraints.MaxNorm(3)\n",
        "          ))\n",
        "  model.add(\n",
        "        layers.Conv2D(\n",
        "          64,\n",
        "          (5, 5),\n",
        "          activation=\"relu\",\n",
        "          padding=\"valid\",\n",
        "          kernel_constraint=constraints.MaxNorm(3)\n",
        "        ))\n",
        "  \n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout({{uniform(0.77, 0.87)}}))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  model.add(layers.Dense(512, activation=\"relu\", kernel_constraint=constraints.MaxNorm(3)))\n",
        "  model.add(layers.Dropout({{uniform(0.21, 0.31)}}))\n",
        "\n",
        "  model.add(layers.Dense(256, activation=\"relu\", kernel_constraint=constraints.MaxNorm(3)))\n",
        "  model.add(layers.Dropout({{uniform(0.57, 0.67)}}))\n",
        "\n",
        "  model.add(layers.Dense(3, activation=\"softmax\", kernel_constraint=constraints.MaxNorm(3)))\n",
        "\n",
        "  model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "  model.fit(X_train, Y_train,\n",
        "            epochs=60,\n",
        "            verbose=2,\n",
        "            callbacks=[early_stopping],\n",
        "            validation_data=(X_test, Y_test))\n",
        "  score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "  print('Test accuracy:', acc)\n",
        "  return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLav9bYUcO9"
      },
      "source": [
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='CT-Scan.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('CT-Scan.ipynb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpdsN97KYFlG"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=model,\n",
        "                                          data=data,\n",
        "                                          functions=[load_data, process_csv_entry, decode_img, preprocess_images],\n",
        "                                          max_evals=30,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='CT-Scan',\n",
        "                                          trials=Trials())\n",
        "\n",
        "print(best_run, best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnaoo45EoLT_"
      },
      "source": [
        "Un test preliminar:\n",
        "```\n",
        "100%|██████████| 10/10 [24:24<00:00, 146.50s/it, best loss: -0.7806666493415833]\n",
        "{'Dropout': 0.7646166765488501, 'Dropout_1': 0.41266207281071243, 'Dropout_2': 0.4844455237320119, 'Dropout_3': 0.026079803111884514}\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBXz3-68t4QR"
      },
      "source": [
        "Test 2:\n",
        "```\n",
        "100%|██████████| 100/100 [3:41:10<00:00, 132.71s/it, best loss: -0.8006666898727417]\n",
        "{'Dropout': 0.1878338127435366, 'Dropout_1': 0.8293042185943654, 'Dropout_2': 0.2698783541301023, 'Dropout_3': 0.6213265636979889}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X41UUTYlogqS"
      },
      "source": [
        "Am incercat optimizarea prin alegerea unui dropout intr un interval de 5% in jurul dropout-ului care a dus la acuratete de 80%. Obtinem:\n",
        "```\n",
        "100%|██████████| 20/20 [28:29<00:00, 85.48s/it, best loss: -0.7911111116409302]\n",
        "{'Dropout': 0.14849314123467006, 'Dropout_1': 0.8210620702955034, 'Dropout_2': 0.23935245491872076, 'Dropout_3': 0.5726309854371733}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3kiAkm__bHS"
      },
      "source": [
        "kernels = [3, 5, 7, 9, 11]\n",
        "kernel_combinations = [(a, b) for a in kernels for b in kernels]\n",
        "\n",
        "model_patterns = [\n",
        "            f\"CL32C{k1}V~CL32C{k1}V~BN~P2~DO18 -> CL64C{k2}V~CL64C{k2}V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\"\n",
        "            for (k1, k2) in kernel_combinations\n",
        "]\n",
        "\n",
        "model_comparison(model_patterns, 30)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}