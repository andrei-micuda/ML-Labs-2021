{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CT-Scan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrei-micuda/ML-Labs-2021/blob/master/CT-Scan/CT_Scan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qROPhEtp1snz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f5190b-c7cc-4793-e36d-241d4b4c9ac4"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_name = \"/content/drive/MyDrive/ct-scan.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall(\"ct-scan\")\n",
        "  print('Done')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLLNu-HM7xKU"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from tensorflow.keras import layers, models, preprocessing, callbacks, regularizers, constraints\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_height, img_width, img_channels = 50, 50, 1\n",
        "\n",
        "\n",
        "def process_csv_entry(entry):\n",
        "    img_path, label = entry.strip().split(\",\")\n",
        "    return img_path, int(label)\n",
        "\n",
        "def decode_img(img):\n",
        "  img = PIL.Image.open(img)\n",
        "  return np.asarray(img)\n",
        "\n",
        "def load_data(dir_name, csv_file, has_labels=True):\n",
        "  features = []\n",
        "  if has_labels:\n",
        "    labels = []\n",
        "  with open(csv_file, \"r\") as fin:\n",
        "    for entry in fin:\n",
        "      img_path = entry.strip()\n",
        "      if has_labels:\n",
        "        img_path, label = process_csv_entry(entry)\n",
        "      \n",
        "      img = decode_img(dir_name + \"/\" + img_path)\n",
        "      features.append(img)\n",
        "      if has_labels:\n",
        "        labels.append(label)\n",
        "  if has_labels:\n",
        "    return np.stack(features), np.stack(labels)\n",
        "  return np.stack(features)\n",
        "\n",
        "def preprocess_images(imgs):\n",
        "  processed_images = np.copy(imgs)\n",
        "  processed_images = processed_images / 255.0\n",
        "  # processed_images = 255 - processed_images\n",
        "  # mean = np.mean(processed_images, axis=(1, 2), keepdims=True)\n",
        "  # std = np.std(processed_images, axis=(1, 2), keepdims=True)\n",
        "  # processed_images = (processed_images - mean) / std\n",
        "  return processed_images\n",
        "  # ones = np.ones(2500).reshape((50, 50))\n",
        "  # return np.subtract(ones, processed_images)\n",
        "\n",
        "\n",
        "def show_data_sample(imgs, labels):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    # ones = np.ones(2500).reshape((50, 50))\n",
        "    plt.imshow(imgs[i])\n",
        "    # plt.imshow(np.subtract(ones, imgs[i]))\n",
        "    # plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "  plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oigUuBqdc5"
      },
      "source": [
        "class_names = [\"native\", \"arterial\", \"venous\"]\n",
        "\n",
        "train_ds, train_labels = load_data(r\"/content/ct-scan/train\", r\"/content/ct-scan/train.txt\")\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "# show_data_sample(train_ds, train_labels)\n",
        "\n",
        "validation_ds, validation_labels = load_data(r\"/content/ct-scan/validation\", r\"/content/ct-scan/validation.txt\")\n",
        "validation_labels = tf.keras.utils.to_categorical(validation_labels)\n",
        "\n",
        "test_ds = load_data(r\"/content/ct-scan/test\", r\"/content/ct-scan/test.txt\", has_labels=False)\n",
        "\n",
        "train_images = tf.expand_dims(preprocess_images(train_ds), axis=-1)\n",
        "validation_images = tf.expand_dims(preprocess_images(validation_ds), axis=-1)\n",
        "test_images = tf.expand_dims(preprocess_images(test_ds), axis=-1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V4fnKwS7E6E"
      },
      "source": [
        "We are going to make 2 utility functions for quick and dirty model testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CVD-Pnp7N6x"
      },
      "source": [
        "def add_layer(model, layer, is_input_layer=False, is_output_layer=False):\n",
        "  weight_decay = 1e-4\n",
        "  parts = [part.strip() for part in layer.split(\"~\")]\n",
        "  for part in parts:\n",
        "    if part.startswith(\"CL\"):\n",
        "      part = part[2:]\n",
        "      filters, kernel_size_and_padding = part.split(\"C\")\n",
        "      filters = int(filters)\n",
        "      kernel_size, padd = int(kernel_size_and_padding[:-1]), kernel_size_and_padding[-1]\n",
        "      if is_input_layer:\n",
        "        model.add(\n",
        "          layers.Conv2D(\n",
        "            filters,\n",
        "            (kernel_size, kernel_size),\n",
        "            activation=\"relu\",\n",
        "            input_shape=(img_height, img_width, img_channels),\n",
        "            padding=\"same\" if padd == \"S\" else \"valid\"\n",
        "            # kernel_regularizer=regularizers.l2(),\n",
        "          )\n",
        "          )\n",
        "      else:\n",
        "        model.add(\n",
        "          layers.Conv2D(\n",
        "            filters,\n",
        "            (kernel_size, kernel_size),\n",
        "            activation=\"relu\",\n",
        "            padding=\"same\" if padd == \"S\" else \"valid\"\n",
        "            # kernel_regularizer=regularizers.l2(weight_decay),\n",
        "            )\n",
        "        )\n",
        "    elif part.startswith(\"P\"):\n",
        "      pool_size = int(part[1:])\n",
        "      # model.add(layers.AvgPool2D(pool_size=(pool_size, pool_size)))\n",
        "      model.add(layers.MaxPool2D(pool_size=(pool_size, pool_size)))\n",
        "    elif part.startswith(\"BN\"):\n",
        "      if is_input_layer:\n",
        "        model.add(layers.BatchNormalization(input_shape=(img_height, img_width, img_channels)))\n",
        "      else:\n",
        "        model.add(layers.BatchNormalization())\n",
        "    elif part.startswith(\"DO\"):\n",
        "      rate = float(part[2:]) / 100.0\n",
        "      if is_input_layer:\n",
        "        model.add(layers.Dropout(rate, input_shape=(img_height, img_width, img_channels)))\n",
        "      else:\n",
        "        model.add(layers.Dropout(rate))\n",
        "    elif part.startswith(\"F\"):\n",
        "      model.add(layers.Flatten())\n",
        "    elif part.startswith(\"D\"):\n",
        "      units = int(part[1:])\n",
        "      model.add(\n",
        "          layers.Dense(\n",
        "              units,\n",
        "              activation=\"softmax\" if is_output_layer else \"relu\",\n",
        "              kernel_constraint=constraints.MaxNorm(3),\n",
        "          )\n",
        "      )\n",
        "\n",
        "\n",
        "def create_model(pattern):\n",
        "  model = models.Sequential()\n",
        "  layers = [layer.strip() for layer in pattern.split(\"->\")]\n",
        "  num_layers = len(layers)\n",
        "  # model.add(\n",
        "  #   tf.keras.layers.experimental.preprocessing.Normalization(\n",
        "  #       input_shape=(50, 50, 1)\n",
        "  #   )\n",
        "  # )\n",
        "  # model.add(tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1))\n",
        "  for i, layer in enumerate(layers):\n",
        "    add_layer(model, layer, is_input_layer=(i == 0), is_output_layer=(i == num_layers - 1))\n",
        "  # model.compile(\n",
        "  #   optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "  #   loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "  #   metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyPpoCJd7sQx"
      },
      "source": [
        "callbacks = [           \n",
        "    tf.keras.callbacks.ModelCheckpoint('/content/ct-scan/best-weights.h5',\n",
        "      save_weights_only=True,\n",
        "      monitor='val_accuracy',\n",
        "      mode='max',\n",
        "      save_best_only=True),\n",
        "    # tf.keras.callbacks.EarlyStopping(\n",
        "    #                     monitor='val_accuracy',\n",
        "    #                     mode=\"max\",\n",
        "    #                     patience=10,\n",
        "    #                     restore_best_weights=True\n",
        "    #                 )\n",
        "]\n",
        "\n",
        "def model_testing(model_pattern, epochs, show_graphs=True):\n",
        "  # model_patterns = [\"CL48C5~P2~BN~DO1 -> CL64C5~P2~BN~DO1 -> CL128C5~BN~DO1 -> F -> D512 -> D512 -> D3\"]\n",
        "  model = create_model(model_pattern)\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0017, epsilon=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "  # model.summary()\n",
        "\n",
        "  datagen = preprocessing.image.ImageDataGenerator(\n",
        "    # height_shift_range=[-5, 5],\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    # featurewise_center=True,\n",
        "    # featurewise_std_normalization=True\n",
        "    # zca_whitening=True\n",
        "    # zoom_range=[0.7, 1.0]\n",
        "  )\n",
        "  datagen.fit(train_images)\n",
        "  train_images_it = datagen.flow(train_images, train_labels)\n",
        "  validation_images_it = datagen.flow(validation_images, validation_labels)\n",
        "\n",
        "\n",
        "  history = model.fit(\n",
        "    train_images_it,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_images_it,\n",
        "    callbacks=callbacks,\n",
        "    # steps_per_epoch=468,\n",
        "    shuffle=True,\n",
        "  )\n",
        "\n",
        "  if show_graphs:\n",
        "    # PLOT ACCURACIES\n",
        "    fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 12))\n",
        "    fig.suptitle(model_pattern)\n",
        "    ax1.plot(history.history[\"val_accuracy\"], linestyle=\"solid\", color=\"orange\")\n",
        "    ax1.plot(history.history[\"accuracy\"], linestyle=\"solid\", color=\"blue\")\n",
        "    ax1.set_xticks(range((epochs)))\n",
        "    ax1.set_title(\"Accuracies\")\n",
        "    ax1.set_ylabel(\"accuracy\")\n",
        "    ax1.set_xlabel(\"epoch\")\n",
        "    ax1.legend([\"val_accuracy\", \"accuracy\"], loc=\"upper left\")\n",
        "\n",
        "    ax2.plot(history.history[\"val_loss\"], linestyle=\"solid\", color=\"orange\")\n",
        "    ax2.plot(history.history[\"loss\"], linestyle=\"solid\", color=\"blue\")\n",
        "    ax2.set_xticks(range((epochs)))\n",
        "    ax2.set_title(\"Loss\")\n",
        "    ax2.set_ylabel(\"loss\")\n",
        "    ax2.set_xlabel(\"epoch\")\n",
        "    ax2.legend([\"val_loss\", \"loss\"], loc=\"upper left\")\n",
        "    # axes = plt.gca()\n",
        "    # axes.set_ylim([0.98, 1])\n",
        "    plt.show()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ndrEHH7yVx"
      },
      "source": [
        "# model_testing(\"CL12C7~CL12C7~BN~P2~DO50 -> CL24C5~CL24C5~BN~P2~DO50 -> F -> D120~DO50 -> D64~DO50 -> D3\", 50)\n",
        "# model = model_testing(\"CL32C7V~DO25~CL132C7V~DO25~BN~P2 -> CL64C5V~DO25~CL64C5V~DO25~BN~P2 -> F -> D128~DO50 -> D128~DO50 -> D3\", 50)\n",
        "#  model = model_testing(\"CL32C7V~CL32C7V~BN~P2~DO36.1 -> CL64C5V~CL64C5V~BN~P2~DO36.4 -> F -> D128~DO22.7 -> D128~DO27.4 -> D3\", 100, show_graphs=True)\n",
        "# model = model_testing(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D128~DO26 -> D128~DO62 -> D3\", 100, show_graphs=True)\n",
        "model = model_testing(\"BN -> CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 20, show_graphs=True)\n",
        "\n",
        "# {'Dropout': 0.1878338127435366, 'Dropout_1': 0.8293042185943654, 'Dropout_2': 0.2698783541301023, 'Dropout_3': 0.6213265636979889}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHf-gSgFUWYz"
      },
      "source": [
        "# model = model_testing(\"BN -> CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 50, show_graphs=True)\n",
        "# model = model_testing(\"BN -> CL32C7V~CL32C7V~BN~P2 -> CL64C5V~CL64C5V~BN~P2 -> F -> D512 -> D256-> D3\", 20, show_graphs=True)\n",
        "\n",
        "# show_data_sample(test_ds, train_labels)\n",
        "model.load_weights(\"/content/ct-scan/best-weights.h5\")\n",
        "predictions = np.argmax(model.predict(test_images), axis=1)\n",
        "with open(\"/content/ct-scan/test.txt\") as fin:\n",
        "  test_image_names = [line.strip() for line in fin.readlines()]\n",
        "with open(\"/content/ct-scan/submission.txt\", 'w') as fout:\n",
        "  fout.write(\"id,label\\n\")\n",
        "  for i, img in enumerate(test_image_names):\n",
        "    fout.write(f\"{img},{predictions[i]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydj0dRXzDj4A"
      },
      "source": [
        "callbackLst = [           \n",
        "  tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode=\"max\",\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        "  )\n",
        "]\n",
        "\n",
        "def model_predict(model_pattern, epochs):\n",
        "  model = create_model(model_pattern)\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0017, epsilon=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"])\n",
        "  \n",
        "  test_ds = load_data(r\"/content/ct-scan/test\", r\"/content/ct-scan/test.txt\", has_labels=False)\n",
        "\n",
        "  # train_images = tf.expand_dims(preprocess_images(train_ds), axis=-1)\n",
        "  # validation_images = tf.expand_dims(preprocess_images(validation_ds), axis=-1)\n",
        "  # test_images = tf.expand_dims(preprocess_images(test_ds), axis=-1)\n",
        "  train_images = tf.expand_dims(train_ds, axis=-1)\n",
        "  validation_images = tf.expand_dims(validation_ds, axis=-1)\n",
        "  test_images = tf.expand_dims(test_ds, axis=-1)\n",
        "\n",
        "  train_datagen = preprocessing.image.ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15,\n",
        "    # featurewise_center=True,\n",
        "    # featurewise_std_normalization=True,\n",
        "    # rescale=1./255\n",
        "  )\n",
        "  train_datagen.fit(train_images)\n",
        "  train_images_it = train_datagen.flow(train_images, train_labels)\n",
        "\n",
        "\n",
        "  test_datagen = preprocessing.image.ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rescale=1./255\n",
        "  )\n",
        "  test_datagen.fit(train_images)\n",
        "  validation_images_it = test_datagen.flow(validation_images, validation_labels)\n",
        "  test_images_it = test_datagen.flow(test_images)\n",
        "\n",
        "\n",
        "  history = model.fit(\n",
        "    train_images_it,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_images_it,\n",
        "    callbacks=callbackLst,\n",
        "    # steps_per_epoch=468,\n",
        "    # shuffle=True,\n",
        "  )\n",
        "\n",
        "  predictions = np.argmax(model.predict(test_images), axis=1)\n",
        "  with open(\"/content/ct-scan/test.txt\") as fin:\n",
        "    test_image_names = [line.strip() for line in fin.readlines()]\n",
        "  with open(\"/content/ct-scan/submission.txt\", 'w') as fout:\n",
        "    fout.write(\"id,label\\n\")\n",
        "    for i, img in enumerate(test_image_names):\n",
        "      fout.write(f\"{img},{predictions[i]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBB8izkUROaC"
      },
      "source": [
        "model_predict(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KFB6-AvYqXg"
      },
      "source": [
        "callbackLst = [             \n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        mode=\"max\",\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "]\n",
        "\n",
        "def lr_comparison(model_pattern, epochs):\n",
        "    lrs = [1e-2]\n",
        "    history = [0] * len(lrs)\n",
        "    for i, lr in enumerate(lrs):\n",
        "        model = create_model(model_pattern)\n",
        "        model.compile(\n",
        "          optimizer=tf.keras.optimizers.Adam(learning_rate=0.0017, epsilon=0.001),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics=[\"accuracy\"])\n",
        "\n",
        "        # model.summary()\n",
        "\n",
        "        datagen = preprocessing.image.ImageDataGenerator(\n",
        "          # height_shift_range=[-5, 5],\n",
        "          horizontal_flip=True,\n",
        "          rotation_range=15,\n",
        "          # featurewise_center=True,\n",
        "          # featurewise_std_normalization=True\n",
        "          # zca_whitening=True\n",
        "          # zoom_range=[0.7, 1.0]\n",
        "        )\n",
        "        datagen.fit(train_images)\n",
        "        train_images_it = datagen.flow(train_images, train_labels)\n",
        "        validation_images_it = datagen.flow(validation_images, validation_labels)\n",
        "\n",
        "\n",
        "        history[i] = model.fit(\n",
        "          train_images_it,\n",
        "          epochs=epochs,\n",
        "          validation_data=validation_images_it,\n",
        "          callbacks=callbacks,\n",
        "          # steps_per_epoch=468,\n",
        "          shuffle=True,\n",
        "        )\n",
        "\n",
        "    styles = [\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "    ]\n",
        "\n",
        "    # PLOT ACCURACIES\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(len(lrs)):\n",
        "        plt.plot(\n",
        "            history[i].history[\"val_accuracy\"],\n",
        "            linestyle=styles[i],\n",
        "            color=np.random.rand(\n",
        "                3,\n",
        "            ),\n",
        "        )\n",
        "    plt.title(\"Model Architecture\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend(lrs, loc=\"upper left\")\n",
        "    # axes = plt.gca()\n",
        "    # axes.set_ylim([0.98, 1])\n",
        "    plt.show()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOo3f-3paZ1M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "8a0e2c29-6bae-4976-a485-bf779f3059ff"
      },
      "source": [
        "lr_comparison(\"BN -> CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 30)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 9s 17ms/step - loss: 1.7005 - accuracy: 0.3487 - val_loss: 1.0912 - val_accuracy: 0.3638\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 1.0894 - accuracy: 0.3849 - val_loss: 1.0835 - val_accuracy: 0.4198\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 1.0348 - accuracy: 0.4567 - val_loss: 0.9576 - val_accuracy: 0.5007\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.9842 - accuracy: 0.4968 - val_loss: 0.8219 - val_accuracy: 0.5911\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.9317 - accuracy: 0.5321 - val_loss: 0.8565 - val_accuracy: 0.5896\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.9013 - accuracy: 0.5502 - val_loss: 0.7651 - val_accuracy: 0.6213\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.8673 - accuracy: 0.5824 - val_loss: 0.7737 - val_accuracy: 0.6289\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 8s 17ms/step - loss: 0.8384 - accuracy: 0.5980 - val_loss: 0.7763 - val_accuracy: 0.5896\n",
            "Epoch 9/30\n",
            "166/469 [=========>....................] - ETA: 4s - loss: 0.8366 - accuracy: 0.6102"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4b626bbb5295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BN -> CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-0b96612b0e73>\u001b[0m in \u001b[0;36mlr_comparison\u001b[0;34m(model_pattern, epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0;31m# steps_per_epoch=468,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-UJyJsUmazD"
      },
      "source": [
        "callbackLst = [             \n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        mode=\"max\",\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "]\n",
        "\n",
        "def epsilon_comparison(model_pattern, epochs):\n",
        "    epsilons = [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
        "    history = [0] * len(epsilons)\n",
        "    for i, epsilon in enumerate(epsilons):\n",
        "        model = create_model(model_pattern)\n",
        "        model.compile(\n",
        "          optimizer=tf.keras.optimizers.Adam(learning_rate=0.0017, epsilon=epsilon),\n",
        "          loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics=[\"accuracy\"])\n",
        "\n",
        "        # model.summary()\n",
        "\n",
        "        train_images = tf.expand_dims(preprocess_images(train_ds), axis=-1)\n",
        "        datagen = preprocessing.image.ImageDataGenerator(\n",
        "            # height_shift_range=[-5, 5],\n",
        "            horizontal_flip=True,\n",
        "            rotation_range=15,\n",
        "            # vertical_flip=True,\n",
        "            # zoom_range=[0.8, 1.2]\n",
        "        )\n",
        "        train_images_it = datagen.flow(tf.expand_dims(train_ds, axis=-1), train_labels)\n",
        "        validation_images = tf.expand_dims(preprocess_images(validation_ds), axis=-1)\n",
        "\n",
        "        history[i] = model.fit(\n",
        "            train_images_it,\n",
        "            epochs=epochs,\n",
        "            validation_data=(validation_images, validation_labels),\n",
        "            callbacks=callbackLst,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "    styles = [\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "        \"dotted\",\n",
        "        \"dashed\",\n",
        "        \"dashdot\",\n",
        "        \"solid\",\n",
        "    ]\n",
        "\n",
        "    # PLOT ACCURACIES\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(len(epsilons)):\n",
        "        plt.plot(\n",
        "            history[i].history[\"val_accuracy\"],\n",
        "            linestyle=styles[i],\n",
        "            color=np.random.rand(\n",
        "                3,\n",
        "            ),\n",
        "        )\n",
        "    plt.title(\"Model Architecture\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend(epsilons, loc=\"upper left\")\n",
        "    # axes = plt.gca()\n",
        "    # axes.set_ylim([0.98, 1])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faG3n_ffoP-F"
      },
      "source": [
        "epsilon_comparison(\"CL32C7V~CL32C7V~BN~P2~DO18 -> CL64C5V~CL64C5V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\", 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ9YfANzSg6f"
      },
      "source": [
        "Vom folosi `hyperas` pentru a optimiza hyperparametrii modelelor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCyAKQvhSnFR"
      },
      "source": [
        "!pip install hyperas\n",
        "!pip install hyperopt\n",
        "from hyperopt import Trials, STATUS_OK, tpe\n",
        "from hyperas import optim\n",
        "from hyperas.distributions import choice, uniform\n",
        "\n",
        "def data():\n",
        "  '''\n",
        "  Data providing function:\n",
        "  This function is separated from model() so that hyperopt\n",
        "  won't reload data for each evaluation run.\n",
        "  '''\n",
        "  (X_train, Y_train) = load_data(r\"/content/ct-scan/train\", r\"/content/ct-scan/train.txt\")\n",
        "  (X_test, Y_test) = load_data(r\"/content/ct-scan/validation\", r\"/content/ct-scan/validation.txt\")\n",
        "\n",
        "  X_train = tf.expand_dims(preprocess_images(X_train), axis=-1)\n",
        "  X_test = tf.expand_dims(preprocess_images(X_test), axis=-1)\n",
        "\n",
        "\n",
        "  Y_train = tf.keras.utils.to_categorical(Y_train)\n",
        "  Y_test = tf.keras.utils.to_categorical(Y_test)\n",
        "  return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test):\n",
        "  '''\n",
        "  Model providing function:\n",
        "  Create Keras model with double curly brackets dropped-in as needed.\n",
        "  Return value has to be a valid python dictionary with two customary keys:\n",
        "      - loss: Specify a numeric evaluation metric to be minimized\n",
        "      - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
        "  The last one is optional, though recommended, namely:\n",
        "      - model: specify the model just created so that we can later use it again.\n",
        "  '''\n",
        "  # \"CL32C7V~CL32C7V~BN~P2~DO50 -> CL64C5V~CL64C5V~BN~P2~DO50 -> F -> D128~DO50 -> D128~DO50 -> D3\"\n",
        "\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor='val_accuracy',\n",
        "                        mode=\"max\",\n",
        "                        patience=5,\n",
        "                        restore_best_weights=True\n",
        "                    )\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(\n",
        "          layers.Conv2D(\n",
        "            32,\n",
        "            (7, 7),\n",
        "            input_shape=(50, 50, 1),\n",
        "            activation=\"relu\",\n",
        "            padding=\"valid\",\n",
        "            kernel_constraint=constraints.MaxNorm(3)\n",
        "          ))\n",
        "  model.add(\n",
        "          layers.Conv2D(\n",
        "            32,\n",
        "            (7, 7),\n",
        "            activation=\"relu\",\n",
        "            padding=\"valid\",\n",
        "            kernel_constraint=constraints.MaxNorm(3)\n",
        "          ))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout({{uniform(0.13, 0.23)}}))\n",
        "\n",
        "  model.add(\n",
        "          layers.Conv2D(\n",
        "            64,\n",
        "            (5, 5),\n",
        "            activation=\"relu\",\n",
        "            padding=\"valid\",\n",
        "            kernel_constraint=constraints.MaxNorm(3)\n",
        "          ))\n",
        "  model.add(\n",
        "        layers.Conv2D(\n",
        "          64,\n",
        "          (5, 5),\n",
        "          activation=\"relu\",\n",
        "          padding=\"valid\",\n",
        "          kernel_constraint=constraints.MaxNorm(3)\n",
        "        ))\n",
        "  \n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout({{uniform(0.77, 0.87)}}))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "\n",
        "  model.add(layers.Dense(512, activation=\"relu\", kernel_constraint=constraints.MaxNorm(3)))\n",
        "  model.add(layers.Dropout({{uniform(0.21, 0.31)}}))\n",
        "\n",
        "  model.add(layers.Dense(256, activation=\"relu\", kernel_constraint=constraints.MaxNorm(3)))\n",
        "  model.add(layers.Dropout({{uniform(0.57, 0.67)}}))\n",
        "\n",
        "  model.add(layers.Dense(3, activation=\"softmax\", kernel_constraint=constraints.MaxNorm(3)))\n",
        "\n",
        "  model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "  model.fit(X_train, Y_train,\n",
        "            epochs=60,\n",
        "            verbose=2,\n",
        "            callbacks=[early_stopping],\n",
        "            validation_data=(X_test, Y_test))\n",
        "  score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
        "  print('Test accuracy:', acc)\n",
        "  return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLav9bYUcO9"
      },
      "source": [
        "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy/download the file\n",
        "fid = drive.ListFile({'q':\"title='CT-Scan.ipynb'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('CT-Scan.ipynb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpdsN97KYFlG"
      },
      "source": [
        "best_run, best_model = optim.minimize(model=model,\n",
        "                                          data=data,\n",
        "                                          functions=[load_data, process_csv_entry, decode_img, preprocess_images],\n",
        "                                          max_evals=30,\n",
        "                                          algo=tpe.suggest,\n",
        "                                          notebook_name='CT-Scan',\n",
        "                                          trials=Trials())\n",
        "\n",
        "print(best_run, best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnaoo45EoLT_"
      },
      "source": [
        "Un test preliminar:\n",
        "```\n",
        "100%|██████████| 10/10 [24:24<00:00, 146.50s/it, best loss: -0.7806666493415833]\n",
        "{'Dropout': 0.7646166765488501, 'Dropout_1': 0.41266207281071243, 'Dropout_2': 0.4844455237320119, 'Dropout_3': 0.026079803111884514}\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBXz3-68t4QR"
      },
      "source": [
        "Test 2:\n",
        "```\n",
        "100%|██████████| 100/100 [3:41:10<00:00, 132.71s/it, best loss: -0.8006666898727417]\n",
        "{'Dropout': 0.1878338127435366, 'Dropout_1': 0.8293042185943654, 'Dropout_2': 0.2698783541301023, 'Dropout_3': 0.6213265636979889}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X41UUTYlogqS"
      },
      "source": [
        "Am incercat optimizarea prin alegerea unui dropout intr un interval de 5% in jurul dropout-ului care a dus la acuratete de 80%. Obtinem:\n",
        "```\n",
        "100%|██████████| 20/20 [28:29<00:00, 85.48s/it, best loss: -0.7911111116409302]\n",
        "{'Dropout': 0.14849314123467006, 'Dropout_1': 0.8210620702955034, 'Dropout_2': 0.23935245491872076, 'Dropout_3': 0.5726309854371733}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3kiAkm__bHS"
      },
      "source": [
        "kernels = [3, 5, 7, 9, 11]\n",
        "kernel_combinations = [(a, b) for a in kernels for b in kernels]\n",
        "\n",
        "model_patterns = [\n",
        "            f\"CL32C{k1}V~CL32C{k1}V~BN~P2~DO18 -> CL64C{k2}V~CL64C{k2}V~BN~P2~DO82 -> F -> D512~DO26 -> D256~DO62 -> D3\"\n",
        "            for (k1, k2) in kernel_combinations\n",
        "]\n",
        "\n",
        "model_comparison(model_patterns, 30)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}